events {
  worker_connections 1024;
}
worker_processes 2;

error_log stderr;

http {
  resolver 127.0.0.11 ipv6=off;

  lua_package_path "/usr/local/openresty/lualib/?.lua;/usr/local/openresty/luajit/share/lua/5.1/?.lua;/lua/src/?.lua";
  lua_package_cpath "/usr/local/openresty/lualib/?.so;/usr/local/openresty/luajit/lib/lua/5.1/?.so;";

  lua_shared_dict redis_cluster_slot_locks 100k;

  init_by_lua_block {
    config = {
      name = "redis-cluster",
      serv_list = {
        { ip = "redis_cluster", port = 7000 },
      },
      keepalive_timeout = 60000,
      keepalive_cons = 1000,
      connection_timout = 1000,
      max_redirection = 5,
    }

    redis_cluster = require "resty-redis-cluster"
    edge_computing = require "resty-edge-computing"
  }

  upstream backend {
    server ingest;
  }

  proxy_cache_path /tmp levels=1:2 keys_zone=my_cache:10m max_size=1g inactive=10m use_temp_path=off;
  server {
    listen 8080;

    location / {
      proxy_cache my_cache;
      proxy_cache_lock on;

      proxy_cache_lock_timeout 2s;
      proxy_cache_use_stale error timeout updating invalid_header;

      proxy_ignore_headers Cache-Control;
      proxy_cache_valid any 2s;

      add_header X-Cache-Status $upstream_cache_status;
      proxy_pass http://backend;
    }

    location /app {
      alias /usr/local/openresty/nginx/;
    }

    rewrite_by_lua_block {
      local redis_client = redis_cluster:new(config)

      local status, err = edge_computing.start(redis_client)
      if not status then
        ngx.log(ngx.ERR, " edge_computing.start error ", err)
      end

      local status, errs = edge_computing.execute()
      if errs ~= {} then
        for _, err in ipairs(errs) do
          ngx.log(ngx.ERR, " edge_computing.execute error ", err)
        end
      end
    }
  }
}
